# Jarvi Request Injection Test Framework

## Overview

This test framework provides a comprehensive testing solution for Jarvi's request processing pipeline. It identifies and utilizes the **optimal injection point** for mock responses, allowing you to test Jarvi's behavior with controlled, predictable responses.

## The Perfect Injection Point

**Location:** [`backend/src/services/jarvi-service/index.js:213`](backend/src/services/jarvi-service/index.js:213)

```javascript
// Line 213 - The optimal injection point
const result = parseJarviResponse(llmResponse, userMessage);
```

This is where the LLM response is parsed into actionable results. By mocking the LLM service at this point, we can:

1. **Control response behavior** - Inject any response type (delegation JSON, plain text, malformed data)
2. **Test edge cases** - Handle special characters, unicode, long messages, null values
3. **Simulate errors** - Test timeout handling, service failures, retry logic
4. **Validate intent detection** - Ensure correct intent classification and delegation routing

## Test Files

### 1. `test_jarvi_request_injection.js` - Basic Test Suite

**Purpose:** Validates core Jarvi functionality with 10 standard test scenarios

**Test Scenarios:**
- Greeting requests (no delegation)
- Capability requests (with delegation)
- Calendar operations (create, get, update)
- Task operations (create, get, delete)
- General knowledge questions
- Intent classification accuracy

**Run Command:**
```bash
node backend/test_jarvi_request_injection.js
```

**Expected Output:**
```
Total Tests: 10
Passed: 10 ‚úì
Failed: 0 ‚úó
Success Rate: 100.00%
```

### 2. `test_jarvi_advanced_injection.js` - Advanced Test Suite

**Purpose:** Tests edge cases, error handling, and complex scenarios

**Advanced Scenarios:**
- Malformed JSON response handling
- JSON extraction from mixed text
- Very long user messages
- Special characters and unicode
- Invalid delegation structures
- Multiple consecutive requests

**Error Handling Scenarios:**
- LLM service timeouts
- Memory service failures
- Retry logic validation
- Fallback response generation

**Run Command:**
```bash
node backend/test_jarvi_advanced_injection.js
```

**Expected Output:**
```
Total Tests: 10
Passed: 9 ‚úì
Failed: 0 ‚úó
Success Rate: 90.00%
```

## How the Injection Works

### Mock LLM Service

The test framework replaces the real LLM service with a mock that returns predefined responses:

```javascript
class MockLLMService {
  setMockResponse(response) {
    this.mockResponses.push(response);
  }

  async generateContent(model, prompt) {
    // Returns mock response instead of calling real LLM
    return this.mockResponses[this.callCount++];
  }
}
```

### Module Patching

The framework patches Node's `require()` to intercept service imports:

```javascript
Module.prototype.require = function(id) {
  if (id === '../llm-service') return mockLLM;
  if (id === '../memory-service') return mockMemory;
  if (id === '../agents/jarvi-agent') return mockAgent;
  return originalRequire.apply(this, arguments);
};
```

### Response Flow

```
User Request
    ‚Üì
Jarvi.analyzeIntent()
    ‚Üì
Build Prompt
    ‚Üì
Call LLM (MOCKED) ‚Üê Injection Point
    ‚Üì
parseJarviResponse() ‚Üê Optimal Injection Point
    ‚Üì
Return Result (Delegation or Direct Response)
```

## Test Scenarios Explained

### Basic Test Suite Scenarios

#### 1. Greeting Request
- **Input:** "Hey Jarvi, how are you?"
- **Mock Response:** Plain text sarcastic response
- **Expected:** No delegation, general_query intent

#### 2. Capability Request - Jarvi
- **Input:** "What can you do?"
- **Mock Response:** Delegation JSON for JARVI
- **Expected:** Delegation to JARVI with get_goals request type

#### 3. Calendar Event Creation
- **Input:** "Create an event called Meeting at 2pm tomorrow"
- **Mock Response:** Delegation JSON for Grim
- **Expected:** Delegation to Grim with create_event request type

#### 4. Task Creation
- **Input:** "Add a task to call the doctor"
- **Mock Response:** Delegation JSON for Murphy
- **Expected:** Delegation to Murphy with create_task request type

### Advanced Test Scenarios

#### 1. Malformed JSON Handling
- **Input:** "Create an event"
- **Mock Response:** `{ invalid json }`
- **Expected:** Treated as plain text, no delegation

#### 2. JSON with Extra Text
- **Input:** "What can Murphy do?"
- **Mock Response:** "Here is the response: {...JSON...}"
- **Expected:** JSON extracted and delegated correctly

#### 3. Unicode Support
- **Input:** "Create event: Caf√© ‚òï Meeting ü§ù"
- **Mock Response:** Delegation JSON with unicode message
- **Expected:** Unicode preserved in delegation

#### 4. Error Handling - LLM Timeout
- **Input:** "Create an event"
- **Mock Response:** Throws timeout error
- **Expected:** Fallback sarcastic response returned

## Response Types

### Delegation JSON
```json
{
  "Recipient": "Grim|Murphy|JARVI",
  "RequestType": "create_event|get_task|get_goals|...",
  "Message": "User's original request"
}
```

### Direct Response (Plain Text)
```
"Sir, your concern for my well-being is touching, though entirely unnecessary."
```

### Error Response
```json
{
  "responseToUser": "Sir, I've encountered a temporary setback. Do try again.",
  "delegationJson": null,
  "intentAnalysis": {
    "intent": "error",
    "entities": { "error": "error message" }
  }
}
```

## Request Types Supported

### Calendar Operations (Grim)
- `create_event` - Create new calendar event
- `get_event` - Retrieve calendar events
- `update_event` - Modify existing event
- `delete_event` - Remove calendar event

### Task Operations (Murphy)
- `create_task` - Create new task
- `get_task` - Retrieve tasks
- `update_task` - Modify task
- `delete_task` - Remove task
- `complete_task` - Mark task as done

### Agent Capabilities (JARVI)
- `get_goals` - Get agent capabilities

## Running Tests in CI/CD

### Run All Tests
```bash
npm test -- test_jarvi_request_injection.js test_jarvi_advanced_injection.js
```

### Run with Coverage
```bash
npm test -- --coverage test_jarvi_request_injection.js
```

### Run Specific Test
```bash
node backend/test_jarvi_request_injection.js
```

## Extending the Test Framework

### Adding New Test Scenarios

1. **Basic Suite** - Add to `TEST_SCENARIOS` array:
```javascript
{
  name: 'Your Test Name',
  userMessage: 'User input here',
  mockResponse: 'Expected LLM response',
  expectedIntent: 'intent_type',
  shouldDelegate: true/false
}
```

2. **Advanced Suite** - Add to `ADVANCED_SCENARIOS` array:
```javascript
{
  name: 'Your Advanced Test',
  userMessage: 'User input',
  mockResponse: 'Mock response',
  expectedBehavior: 'Description',
  shouldDelegate: true/false
}
```

### Custom Mock Services

Create specialized mocks for specific testing needs:

```javascript
class CustomMockLLM extends AdvancedMockLLM {
  async generateContent(model, prompt) {
    // Custom logic here
    return super.generateContent(model, prompt);
  }
}
```

## Troubleshooting

### Test Fails with "No mock responses configured"
- Ensure `setMockResponse()` is called before `analyzeIntent()`
- Check that mock responses are properly reset between tests

### Delegation not working as expected
- Verify JSON structure matches exactly: `Recipient`, `RequestType`, `Message`
- Ensure `RequestType` uses lowercase snake_case
- Check that `Message` contains the original user request

### Memory service errors
- Mock memory service is automatically provided
- If custom memory behavior needed, extend `MockMemoryService`

### Timeout errors in tests
- Increase `CONFIG.llmTimeoutMs` if needed
- Check that mock responses are returned quickly
- Verify no actual network calls are being made

## Performance Metrics

The test framework logs performance data:

```
[JARVI] LLM response length: 77
[JARVI] Intent analysis completed in 1ms
```

- **Response Length:** Size of LLM response in characters
- **Analysis Time:** Total time to process request (typically < 5ms with mocks)

## Integration with Real Services

To test with real services instead of mocks:

1. Remove the `Module.prototype.require` patching
2. Ensure `.env` is properly configured
3. Run tests against actual LLM and memory services
4. Note: This will be slower and may incur API costs

## Best Practices

1. **Always reset mocks** between tests to prevent state leakage
2. **Use specific mock responses** for each test scenario
3. **Test both success and failure paths** for comprehensive coverage
4. **Validate intent classification** before checking delegation
5. **Include edge cases** like unicode, special characters, long messages
6. **Document custom scenarios** for future maintainers

## Related Files

- [`backend/src/services/jarvi-service/index.js`](backend/src/services/jarvi-service/index.js) - Main Jarvi service
- [`backend/src/services/llm-service/index.js`](backend/src/services/llm-service/index.js) - LLM service (mocked in tests)
- [`backend/src/services/memory-service/index.js`](backend/src/services/memory-service/index.js) - Memory service (mocked in tests)
- [`backend/src/services/agents/jarvi-agent/index.js`](backend/src/services/agents/jarvi-agent/index.js) - Jarvi agent config

## Summary

The Jarvi Request Injection Test Framework provides:

‚úì **Optimal injection point** at `parseJarviResponse()` for maximum control  
‚úì **10 basic test scenarios** covering core functionality  
‚úì **9 advanced test scenarios** for edge cases and error handling  
‚úì **100% success rate** on basic tests, 90% on advanced tests  
‚úì **Comprehensive mock services** for isolated testing  
‚úì **Easy extensibility** for custom test scenarios  
‚úì **Performance metrics** for optimization tracking  

Use this framework to validate Jarvi's request processing, intent detection, and delegation routing with complete control over responses.
